{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e696bff6",
   "metadata": {},
   "source": [
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5c7df7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All imports successful\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score, classification_report, confusion_matrix\n",
    "import lightgbm as lgb\n",
    "import time\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "print(\"✓ All imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf5c0a7",
   "metadata": {},
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9e4ad9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Data loaded: (148670, 34)\n",
      "\n",
      "Dataset shape: 148,670 rows × 34 columns\n",
      "\n",
      "First rows:\n",
      "      ID  year loan_limit             Gender approv_in_adv loan_type  \\\n",
      "0  24890  2019         cf  Sex Not Available         nopre     type1   \n",
      "1  24891  2019         cf               Male         nopre     type2   \n",
      "2  24892  2019         cf               Male           pre     type1   \n",
      "3  24893  2019         cf               Male         nopre     type1   \n",
      "4  24894  2019         cf              Joint           pre     type1   \n",
      "\n",
      "  loan_purpose Credit_Worthiness open_credit business_or_commercial  ...  \\\n",
      "0           p1                l1        nopc                  nob/c  ...   \n",
      "1           p1                l1        nopc                    b/c  ...   \n",
      "2           p1                l1        nopc                  nob/c  ...   \n",
      "3           p4                l1        nopc                  nob/c  ...   \n",
      "4           p1                l1        nopc                  nob/c  ...   \n",
      "\n",
      "   credit_type  Credit_Score  co-applicant_credit_type    age  \\\n",
      "0          EXP           758                       CIB  25-34   \n",
      "1         EQUI           552                       EXP  55-64   \n",
      "2          EXP           834                       CIB  35-44   \n",
      "3          EXP           587                       CIB  45-54   \n",
      "4         CRIF           602                       EXP  25-34   \n",
      "\n",
      "   submission_of_application        LTV Region Security_Type  Status dtir1  \n",
      "0                    to_inst  98.728814  south        direct       1  45.0  \n",
      "1                    to_inst        NaN  North        direct       1   NaN  \n",
      "2                    to_inst  80.019685  south        direct       0  46.0  \n",
      "3                   not_inst  69.376900  North        direct       0  42.0  \n",
      "4                   not_inst  91.886544  North        direct       0  39.0  \n",
      "\n",
      "[5 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "csv_path = r\"C:\\Users\\user\\Documents\\dev\\selastone_loan_default\\archive\"\n",
    "\n",
    "df = pd.read_csv(os.path.join(csv_path, 'Loan_Default.csv'))\n",
    "print(f\"✓ Data loaded: {df.shape}\")\n",
    "print(f\"\\nDataset shape: {df.shape[0]:,} rows × {df.shape[1]} columns\")\n",
    "print(f\"\\nFirst rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6969610",
   "metadata": {},
   "source": [
    "## EXPLORE & CLEAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "27afb21f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "DATA EXPLORATION & CLEANING\n",
      "======================================================================\n",
      "\n",
      "Target Variable (Status):\n",
      "Status\n",
      "0    112031\n",
      "1     36639\n",
      "Name: count, dtype: int64\n",
      "Default Rate: 24.64%\n",
      "\n",
      "Missing Values Summary:\n",
      "Upfront_charges              26.664425\n",
      "Interest_rate_spread         24.644515\n",
      "rate_of_interest             24.509989\n",
      "dtir1                        16.224524\n",
      "LTV                          10.155378\n",
      "property_value               10.155378\n",
      "income                        6.154571\n",
      "loan_limit                    2.249277\n",
      "approv_in_adv                 0.610749\n",
      "submission_of_application     0.134526\n",
      "age                           0.134526\n",
      "loan_purpose                  0.090133\n",
      "Neg_ammortization             0.081388\n",
      "term                          0.027578\n",
      "dtype: float64\n",
      "\n",
      "Dropping 0 columns with >40% missing:\n",
      "[]\n",
      "\n",
      "Dataset shape after cleaning: (148670, 33)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DATA EXPLORATION & CLEANING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check target variable\n",
    "print(f\"\\nTarget Variable (Status):\")\n",
    "print(df['Status'].value_counts())\n",
    "print(f\"Default Rate: {df['Status'].mean():.2%}\")\n",
    "\n",
    "# Remove ID column (not a feature)\n",
    "df = df.drop(['ID'], axis=1)\n",
    "\n",
    "# Missing values\n",
    "print(f\"\\nMissing Values Summary:\")\n",
    "missing_pct = (df.isnull().sum() / len(df) * 100).sort_values(ascending=False)\n",
    "print(missing_pct[missing_pct > 0].head(15))\n",
    "\n",
    "# Drop columns with >40% missing\n",
    "drop_cols = missing_pct[missing_pct > 40].index.tolist()\n",
    "print(f\"\\nDropping {len(drop_cols)} columns with >40% missing:\")\n",
    "print(drop_cols)\n",
    "df = df.drop(columns=drop_cols)\n",
    "\n",
    "print(f\"\\nDataset shape after cleaning: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea54a49",
   "metadata": {},
   "source": [
    "## FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f0122708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "FEATURE ENGINEERING\n",
      "======================================================================\n",
      "Numeric columns (11): ['year', 'loan_amount', 'rate_of_interest', 'Interest_rate_spread', 'Upfront_charges', 'term', 'property_value', 'income', 'Credit_Score', 'LTV', 'dtir1']\n",
      "\n",
      "Categorical columns (21): ['loan_limit', 'Gender', 'approv_in_adv', 'loan_type', 'loan_purpose', 'Credit_Worthiness', 'open_credit', 'business_or_commercial', 'Neg_ammortization', 'interest_only', 'lump_sum_payment', 'construction_type', 'occupancy_type', 'Secured_by', 'total_units', 'credit_type', 'co-applicant_credit_type', 'age', 'submission_of_application', 'Region', 'Security_Type']\n",
      "\n",
      "✓ Missing values filled\n",
      "✓ Created 3 derived features\n",
      "✓ Total numeric features: 14\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FEATURE ENGINEERING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Extract numeric and categorical columns\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Remove target from features\n",
    "if 'Status' in numeric_cols:\n",
    "    numeric_cols.remove('Status')\n",
    "\n",
    "print(f\"Numeric columns ({len(numeric_cols)}): {numeric_cols}\")\n",
    "print(f\"\\nCategorical columns ({len(categorical_cols)}): {categorical_cols}\")\n",
    "\n",
    "# Fill missing numeric values with median\n",
    "for col in numeric_cols:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        df[col].fillna(df[col].median(), inplace=True)\n",
    "\n",
    "# Fill missing categorical values with mode\n",
    "for col in categorical_cols:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "\n",
    "print(f\"\\n✓ Missing values filled\")\n",
    "\n",
    "# Create derived features\n",
    "df['loan_to_income'] = df['loan_amount'] / (df['income'] + 1)\n",
    "df['loan_to_property'] = df['loan_amount'] / (df['property_value'] + 1)\n",
    "df['credit_to_income'] = df['Credit_Score'] / (df['income'] + 1)\n",
    "\n",
    "# Add new features to numeric columns\n",
    "new_features = ['loan_to_income', 'loan_to_property', 'credit_to_income']\n",
    "numeric_cols.extend(new_features)\n",
    "\n",
    "print(f\"✓ Created {len(new_features)} derived features\")\n",
    "print(f\"✓ Total numeric features: {len(numeric_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccd9dea",
   "metadata": {},
   "source": [
    "## PREPARE FEATURES FOR MODELING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6850f11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PREPARE FEATURES\n",
      "======================================================================\n",
      "Features shape: (148670, 35)\n",
      "Target shape: (148670,)\n",
      "Target distribution:\n",
      "  0 (No Default): 112,031\n",
      "  1 (Default): 36,639\n",
      "✓ Encoded 21 categorical columns\n",
      "✓ Handled outliers\n",
      "\n",
      "Final features: ['year', 'loan_amount', 'rate_of_interest', 'Interest_rate_spread', 'Upfront_charges', 'term', 'property_value', 'income', 'Credit_Score', 'LTV', 'dtir1', 'loan_to_income', 'loan_to_property', 'credit_to_income', 'loan_limit', 'Gender', 'approv_in_adv', 'loan_type', 'loan_purpose', 'Credit_Worthiness', 'open_credit', 'business_or_commercial', 'Neg_ammortization', 'interest_only', 'lump_sum_payment', 'construction_type', 'occupancy_type', 'Secured_by', 'total_units', 'credit_type', 'co-applicant_credit_type', 'age', 'submission_of_application', 'Region', 'Security_Type']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PREPARE FEATURES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Separate X and y\n",
    "X = df[numeric_cols + categorical_cols].copy()\n",
    "y = df['Status'].copy()\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"Target distribution:\")\n",
    "print(f\"  0 (No Default): {(y == 0).sum():,}\")\n",
    "print(f\"  1 (Default): {(y == 1).sum():,}\")\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "print(f\"✓ Encoded {len(categorical_cols)} categorical columns\")\n",
    "\n",
    "# Handle outliers (clip at 1st and 99th percentiles)\n",
    "for col in numeric_cols:\n",
    "    q1 = X[col].quantile(0.01)\n",
    "    q99 = X[col].quantile(0.99)\n",
    "    X[col] = X[col].clip(q1, q99)\n",
    "\n",
    "print(f\"✓ Handled outliers\")\n",
    "print(f\"\\nFinal features: {X.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e5d842",
   "metadata": {},
   "source": [
    "## TRAIN-TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dcd91cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TRAIN-TEST SPLIT\n",
      "======================================================================\n",
      "Training set: (118936, 35)\n",
      "  Default rate: 24.64%\n",
      "\n",
      "Test set: (29734, 35)\n",
      "  Default rate: 24.65%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAIN-TEST SPLIT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"  Default rate: {y_train.mean():.2%}\")\n",
    "print(f\"\\nTest set: {X_test.shape}\")\n",
    "print(f\"  Default rate: {y_test.mean():.2%}\")\n",
    "\n",
    "feature_names = X.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9191f5",
   "metadata": {},
   "source": [
    "## SCALE FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ec592c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "SCALE FEATURES\n",
      "======================================================================\n",
      "✓ Features scaled (mean=0, std=1)\n",
      "Training set shape: (118936, 35)\n",
      "Test set shape: (29734, 35)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SCALE FEATURES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"✓ Features scaled (mean=0, std=1)\")\n",
    "print(f\"Training set shape: {X_train_scaled.shape}\")\n",
    "print(f\"Test set shape: {X_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11e48df",
   "metadata": {},
   "source": [
    "## HANDLE CLASS IMBALANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8edff9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "HANDLE CLASS IMBALANCE (SMOTE)\n",
      "======================================================================\n",
      "Before SMOTE:\n",
      "  Shape: (118936, 35)\n",
      "  Defaults: 29,311 (24.64%)\n",
      "\n",
      "After SMOTE:\n",
      "  Shape: (161325, 35)\n",
      "  Defaults: 71,700 (44.44%)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"HANDLE CLASS IMBALANCE (SMOTE)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# smote = SMOTE(random_state=42, k_neighbors=5)\n",
    "smote = SMOTE(\n",
    "    k_neighbors=3,        # Default is 5, try 3 for sparse regions\n",
    "    sampling_strategy=0.8, # 0.8 instead of 1.0 (keep some imbalance)\n",
    "    random_state=42\n",
    ")\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Before SMOTE:\")\n",
    "print(f\"  Shape: {X_train_scaled.shape}\")\n",
    "print(f\"  Defaults: {y_train.sum():,} ({y_train.mean():.2%})\")\n",
    "\n",
    "print(f\"\\nAfter SMOTE:\")\n",
    "print(f\"  Shape: {X_train_balanced.shape}\")\n",
    "print(f\"  Defaults: {y_train_balanced.sum():,} ({y_train_balanced.mean():.2%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea349d7",
   "metadata": {},
   "source": [
    "## BASELINE MODEL (YOUR CURRENT MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "503c1b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "BASELINE LIGHTGBM MODEL (YOUR CURRENT PARAMS)\n",
      "======================================================================\n",
      "Training baseline with your current parameters...\n",
      "  n_estimators: 500\n",
      "  max_depth: 4\n",
      "  learning_rate: 0.03\n",
      "  subsample: 0.7\n",
      "  colsample_bytree: 0.7\n",
      "  min_child_samples: 20\n",
      "  reg_lambda: 1.0\n",
      "  reg_alpha: 0.5\n",
      "  scale_pos_weight: 3.06\n",
      "\n",
      "✓ Baseline model trained\n",
      "\n",
      "Baseline Results:\n",
      "  AUC-ROC:  0.4144\n",
      "  F1-Score: 0.0000\n",
      "  Accuracy: 0.7534\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BASELINE LIGHTGBM MODEL (YOUR CURRENT PARAMS)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Calculate scale_pos_weight for imbalance\n",
    "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "\n",
    "baseline_lgb = lgb.LGBMClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.03,\n",
    "    subsample=0.7,\n",
    "    colsample_bytree=0.7,\n",
    "    min_child_samples=20,\n",
    "    reg_lambda=1.0,\n",
    "    reg_alpha=0.5,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "print(f\"Training baseline with your current parameters...\")\n",
    "print(f\"  n_estimators: 500\")\n",
    "print(f\"  max_depth: 4\")\n",
    "print(f\"  learning_rate: 0.03\")\n",
    "print(f\"  subsample: 0.7\")\n",
    "print(f\"  colsample_bytree: 0.7\")\n",
    "print(f\"  min_child_samples: 20\")\n",
    "print(f\"  reg_lambda: 1.0\")\n",
    "print(f\"  reg_alpha: 0.5\")\n",
    "print(f\"  scale_pos_weight: {scale_pos_weight:.2f}\")\n",
    "\n",
    "baseline_lgb.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Evaluate baseline\n",
    "baseline_pred_proba = baseline_lgb.predict_proba(X_test)[:, 1]\n",
    "baseline_auc = roc_auc_score(y_test, baseline_pred_proba)\n",
    "baseline_f1 = f1_score(y_test, baseline_lgb.predict(X_test))\n",
    "baseline_accuracy = accuracy_score(y_test, baseline_lgb.predict(X_test))\n",
    "\n",
    "print(f\"\\n✓ Baseline model trained\")\n",
    "print(f\"\\nBaseline Results:\")\n",
    "print(f\"  AUC-ROC:  {baseline_auc:.4f}\")\n",
    "print(f\"  F1-Score: {baseline_f1:.4f}\")\n",
    "print(f\"  Accuracy: {baseline_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432f7a9a",
   "metadata": {},
   "source": [
    "## DEFINE HYPERPARAMETER GRID (TUNING YOUR PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "421cf0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "HYPERPARAMETER GRID - TUNING YOUR PARAMETERS\n",
      "======================================================================\n",
      "Hyperparameter Grid (8 parameters):\n",
      "  n_estimators: [300, 400, 500, 600, 700] ← CURRENT\n",
      "  max_depth: [3, 4, 5, 6, 7] ← CURRENT\n",
      "  learning_rate: [0.01, 0.02, 0.03, 0.05, 0.1] ← CURRENT\n",
      "  subsample: [0.6, 0.65, 0.7, 0.75, 0.8] ← CURRENT\n",
      "  colsample_bytree: [0.6, 0.65, 0.7, 0.75, 0.8] ← CURRENT\n",
      "  min_child_samples: [10, 15, 20, 25, 30] ← CURRENT\n",
      "  reg_lambda: [0.5, 1.0, 1.5, 2.0] ← CURRENT\n",
      "  reg_alpha: [0.0, 0.25, 0.5, 1.0] ← CURRENT\n",
      "\n",
      "Total combinations to test: 250,000\n",
      "With 5-fold CV: 1,250,000 model trainings\n",
      "Estimated time: 60-120 minutes (or more)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"HYPERPARAMETER GRID - TUNING YOUR PARAMETERS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Grid of hyperparameters to search (focusing on your parameters)\n",
    "param_grid = {\n",
    "    'n_estimators': [300, 400, 500, 600, 700],          # Currently: 500\n",
    "    'max_depth': [3, 4, 5, 6, 7],                        # Currently: 4\n",
    "    'learning_rate': [0.01, 0.02, 0.03, 0.05, 0.1],     # Currently: 0.03\n",
    "    'subsample': [0.6, 0.65, 0.7, 0.75, 0.8],           # Currently: 0.7\n",
    "    'colsample_bytree': [0.6, 0.65, 0.7, 0.75, 0.8],    # Currently: 0.7\n",
    "    'min_child_samples': [10, 15, 20, 25, 30],          # Currently: 20\n",
    "    'reg_lambda': [0.5, 1.0, 1.5, 2.0],                 # Currently: 1.0\n",
    "    'reg_alpha': [0.0, 0.25, 0.5, 1.0]                  # Currently: 0.5\n",
    "}\n",
    "\n",
    "print(\"Hyperparameter Grid (8 parameters):\")\n",
    "for param, values in param_grid.items():\n",
    "    current = {\n",
    "        'n_estimators': 500,\n",
    "        'max_depth': 4,\n",
    "        'learning_rate': 0.03,\n",
    "        'subsample': 0.7,\n",
    "        'colsample_bytree': 0.7,\n",
    "        'min_child_samples': 20,\n",
    "        'reg_lambda': 1.0,\n",
    "        'reg_alpha': 0.5\n",
    "    }\n",
    "    marker = \" ← CURRENT\" if param in current and current[param] in values else \"\"\n",
    "    print(f\"  {param}: {values}{marker}\")\n",
    "\n",
    "total_combinations = 1\n",
    "for values in param_grid.values():\n",
    "    total_combinations *= len(values)\n",
    "print(f\"\\nTotal combinations to test: {total_combinations:,}\")\n",
    "print(f\"With 5-fold CV: {total_combinations * 5:,} model trainings\")\n",
    "print(f\"Estimated time: 60-120 minutes (or more)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d158181b",
   "metadata": {},
   "source": [
    "## OPTION A - FULL GRIDSEARCHCV (BEST RESULTS, SLOWER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "802b837b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "OPTION A: FULL GRIDSEARCHCV (TAKES 1-2 HOURS)\n",
      "======================================================================\n",
      "\n",
      "⚠️  WARNING: Full grid search with 8 parameters is VERY slow!\n",
      "Uncomment below to run. Otherwise, skip to Option B.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ngrid_search_full = GridSearchCV(\\n    estimator=lgb.LGBMClassifier(\\n        scale_pos_weight=scale_pos_weight,\\n        random_state=42,\\n        n_jobs=-1,\\n        verbose=-1\\n    ),\\n    param_grid=param_grid,\\n    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\\n    scoring=\\'roc_auc\\',\\n    n_jobs=-1,\\n    verbose=1\\n)\\n\\nprint(\"\\nRunning full grid search (this will take 60-120 minutes)...\")\\nstart_time = time.time()\\ngrid_search_full.fit(X_train_balanced, y_train_balanced)\\nelapsed = time.time() - start_time\\n\\nprint(f\"\\n✓ Completed in {elapsed/60:.1f} minutes\")\\nprint(f\"Best CV AUC: {grid_search_full.best_score_:.4f}\")\\nprint(f\"Best parameters: {grid_search_full.best_params_}\")\\n'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"OPTION A: FULL GRIDSEARCHCV (TAKES 1-2 HOURS)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n⚠️  WARNING: Full grid search with 8 parameters is VERY slow!\")\n",
    "print(\"Uncomment below to run. Otherwise, skip to Option B.\")\n",
    "\n",
    "# UNCOMMENT TO RUN FULL GRID SEARCH (NOT RECOMMENDED FOR FIRST TIME)\n",
    "\"\"\"\n",
    "grid_search_full = GridSearchCV(\n",
    "    estimator=lgb.LGBMClassifier(\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1\n",
    "    ),\n",
    "    param_grid=param_grid,\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nRunning full grid search (this will take 60-120 minutes)...\")\n",
    "start_time = time.time()\n",
    "grid_search_full.fit(X_train_balanced, y_train_balanced)\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print(f\"\\n✓ Completed in {elapsed/60:.1f} minutes\")\n",
    "print(f\"Best CV AUC: {grid_search_full.best_score_:.4f}\")\n",
    "print(f\"Best parameters: {grid_search_full.best_params_}\")\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c12a218",
   "metadata": {},
   "source": [
    "## OPTION B - REDUCED GRID (FASTER, RECOMMENDED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "765af507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "OPTION B: REDUCED GRIDSEARCHCV (TAKES 15-30 MINUTES) ⭐ RECOMMENDED\n",
      "======================================================================\n",
      "Reduced Hyperparameter Grid (7 parameters, better values):\n",
      "  max_depth: [3, 4, 5, 6]\n",
      "  learning_rate: [0.02, 0.03, 0.05]\n",
      "  subsample: [0.65, 0.7, 0.75]\n",
      "  colsample_bytree: [0.65, 0.7, 0.75]\n",
      "  min_child_samples: [15, 20, 25]\n",
      "  reg_lambda: [0.5, 1.0, 1.5]\n",
      "  reg_alpha: [0.25, 0.5, 1.0]\n",
      "\n",
      "Total combinations to test: 2,916\n",
      "With 5-fold CV: 14,580 model trainings\n",
      "Estimated time: 15-30 minutes\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"OPTION B: REDUCED GRIDSEARCHCV (TAKES 15-30 MINUTES) ⭐ RECOMMENDED\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Reduced grid: focus on key parameters\n",
    "param_grid_reduced = {\n",
    "    'max_depth': [3, 4, 5, 6],              # Drop 7 (usually overfits)\n",
    "    'learning_rate': [0.02, 0.03, 0.05],   # Drop 0.01, 0.1 (extremes)\n",
    "    'subsample': [0.65, 0.7, 0.75],        # Drop 0.6, 0.8 (extremes)\n",
    "    'colsample_bytree': [0.65, 0.7, 0.75], # Drop 0.6, 0.8 (extremes)\n",
    "    'min_child_samples': [15, 20, 25],     # Drop 10, 30 (extremes)\n",
    "    'reg_lambda': [0.5, 1.0, 1.5],         # Drop 2.0 (extreme)\n",
    "    'reg_alpha': [0.25, 0.5, 1.0]          # Drop 0.0 (no regularization)\n",
    "}\n",
    "\n",
    "print(\"Reduced Hyperparameter Grid (7 parameters, better values):\")\n",
    "for param, values in param_grid_reduced.items():\n",
    "    print(f\"  {param}: {values}\")\n",
    "\n",
    "total_combinations_reduced = 1\n",
    "for values in param_grid_reduced.values():\n",
    "    total_combinations_reduced *= len(values)\n",
    "print(f\"\\nTotal combinations to test: {total_combinations_reduced:,}\")\n",
    "print(f\"With 5-fold CV: {total_combinations_reduced * 5:,} model trainings\")\n",
    "print(f\"Estimated time: 15-30 minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0d58ea",
   "metadata": {},
   "source": [
    "## RUN REDUCED GRIDSEARCHCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "06fa1817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "RUNNING RANDOMIZEDSEARCHCV (3-5 MINUTES)\n",
      "======================================================================\n",
      "Starting random search...\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "\n",
      "✓ Completed in 2.2 minutes\n",
      "  Best AUC: 1.0000\n",
      "  Best params: {'subsample': 0.7, 'reg_lambda': 0.5, 'reg_alpha': 0.5, 'min_child_samples': 25, 'max_depth': 6, 'learning_rate': 0.05, 'colsample_bytree': 0.65}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RUNNING RANDOMIZEDSEARCHCV (3-5 MINUTES)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# param_dist = {\n",
    "#     'max_depth': [3, 4, 5, 6, 7, 8],\n",
    "#     'learning_rate': [0.01, 0.03, 0.05, 0.1, 0.2],\n",
    "#     'num_leaves': [20, 31, 50, 63, 100],\n",
    "#     'subsample': [0.6, 0.7, 0.8, 0.9],\n",
    "# }\n",
    "\n",
    "lgb_base = lgb.LGBMClassifier(\n",
    "    n_estimators=200,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=lgb_base,\n",
    "    param_distributions=param_grid_reduced,\n",
    "    n_iter=20,                 # Only test 20 random combinations\n",
    "    cv=3,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Starting random search...\")\n",
    "start_time = time.time()\n",
    "random_search.fit(X_train_balanced, y_train_balanced)\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n✓ Completed in {elapsed_time/60:.1f} minutes\")\n",
    "print(f\"  Best AUC: {random_search.best_score_:.4f}\")\n",
    "print(f\"  Best params: {random_search.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54574607",
   "metadata": {},
   "source": [
    "## ANALYZE RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "953951a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "RandomizedSearchCV RESULTS\n",
      "======================================================================\n",
      "\n",
      "Best Parameters Found:\n",
      "  colsample_bytree: 0.65\n",
      "  learning_rate: 0.05\n",
      "  max_depth: 6\n",
      "  min_child_samples: 25\n",
      "  reg_alpha: 0.5\n",
      "  reg_lambda: 0.5\n",
      "  subsample: 0.7\n",
      "\n",
      "Best CV Score (AUC-ROC): 1.0000\n",
      "\n",
      "Best Model Test Performance:\n",
      "  AUC-ROC:  0.3899\n",
      "  F1-Score: 0.0000\n",
      "  Accuracy: 0.7534\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RandomizedSearchCV RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nBest Parameters Found:\")\n",
    "best_params = random_search.best_params_\n",
    "for param, value in sorted(best_params.items()):\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "print(f\"\\nBest CV Score (AUC-ROC): {random_search.best_score_:.4f}\")\n",
    "\n",
    "# Get best model\n",
    "best_lgb = random_search.best_estimator_\n",
    "\n",
    "# Evaluate on test set\n",
    "best_pred_proba = best_lgb.predict_proba(X_test)[:, 1]\n",
    "best_auc = roc_auc_score(y_test, best_pred_proba)\n",
    "best_f1 = f1_score(y_test, best_lgb.predict(X_test))\n",
    "best_accuracy = accuracy_score(y_test, best_lgb.predict(X_test))\n",
    "\n",
    "print(f\"\\nBest Model Test Performance:\")\n",
    "print(f\"  AUC-ROC:  {best_auc:.4f}\")\n",
    "print(f\"  F1-Score: {best_f1:.4f}\")\n",
    "print(f\"  Accuracy: {best_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7560df8",
   "metadata": {},
   "source": [
    "## COMPARE BASELINE VS TUNED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f91c37a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "BASELINE vs TUNED COMPARISON\n",
      "======================================================================\n",
      "Evaluating tuned model...\n",
      "\n",
      "Metric Comparison:\n",
      "Metric               Baseline     Tuned        Improvement    \n",
      "------------------------------------------------------------\n",
      "AUC-ROC              0.4144       0.3899       -5.89%\n",
      "F1-Score             0.0000       0.0000       N/A            \n",
      "Accuracy             0.7534       0.7534       +0.00%\n",
      "\n",
      "======================================================================\n",
      "⚠️ Tuning decreased AUC performance\n",
      "  AUC drop: -5.89%\n",
      "  Recommendation: Use baseline model\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BASELINE vs TUNED COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ========== TUNED MODEL EVALUATION ==========\n",
    "print(\"Evaluating tuned model...\")\n",
    "best_pred = best_lgb.predict(X_test)\n",
    "best_pred_proba = best_lgb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "best_auc = roc_auc_score(y_test, best_pred_proba)\n",
    "best_f1 = f1_score(y_test, best_pred)\n",
    "best_accuracy = accuracy_score(y_test, best_pred)\n",
    "\n",
    "# ========== SAFE IMPROVEMENT CALCULATION ==========\n",
    "def safe_improvement(new_val, baseline_val):\n",
    "    \"\"\"Calculate % improvement, handle division by zero\"\"\"\n",
    "    if baseline_val == 0:\n",
    "        return float('inf') if new_val > 0 else 0\n",
    "    return ((new_val - baseline_val) / baseline_val) * 100\n",
    "\n",
    "improvement_auc = safe_improvement(best_auc, baseline_auc)\n",
    "improvement_f1 = safe_improvement(best_f1, baseline_f1)\n",
    "improvement_accuracy = safe_improvement(best_accuracy, baseline_accuracy)\n",
    "\n",
    "# ========== DISPLAY COMPARISON ==========\n",
    "print(f\"\\nMetric Comparison:\")\n",
    "print(f\"{'Metric':<20} {'Baseline':<12} {'Tuned':<12} {'Improvement':<15}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'AUC-ROC':<20} {baseline_auc:<12.4f} {best_auc:<12.4f} {improvement_auc:+.2f}%\")\n",
    "\n",
    "if baseline_f1 > 0:\n",
    "    print(f\"{'F1-Score':<20} {baseline_f1:<12.4f} {best_f1:<12.4f} {improvement_f1:+.2f}%\")\n",
    "else:\n",
    "    print(f\"{'F1-Score':<20} {baseline_f1:<12.4f} {best_f1:<12.4f} {'N/A':<15}\")\n",
    "\n",
    "print(f\"{'Accuracy':<20} {baseline_accuracy:<12.4f} {best_accuracy:<12.4f} {improvement_accuracy:+.2f}%\")\n",
    "\n",
    "# ========== INTERPRETATION ==========\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "if best_auc > baseline_auc:\n",
    "    print(f\"✓ Tuning improved model performance!\")\n",
    "    print(f\"  AUC improvement: {improvement_auc:+.2f}%\")\n",
    "    if improvement_f1 > 0:\n",
    "        print(f\"  F1-Score improvement: {improvement_f1:+.2f}%\")\n",
    "    if improvement_accuracy > 0:\n",
    "        print(f\"  Accuracy improvement: {improvement_accuracy:+.2f}%\")\n",
    "elif best_auc == baseline_auc:\n",
    "    print(f\"~ No change in AUC after tuning\")\n",
    "    print(f\"  Baseline params already near optimal\")\n",
    "else:\n",
    "    print(f\"⚠️ Tuning decreased AUC performance\")\n",
    "    print(f\"  AUC drop: {improvement_auc:.2f}%\")\n",
    "    print(f\"  Recommendation: Use baseline model\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f007fbb",
   "metadata": {},
   "source": [
    "## REMOVE SUSPECTED LEAKY FEATURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "88b63e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "CHECKING FOR DATA LEAKAGE\n",
      "======================================================================\n",
      "\n",
      "Retraining WITHOUT 'Interest_rate_spread'...\n",
      "Original features: 35\n",
      "After removing 'interest_rate_spread': 34\n",
      "Starting random search without leaky feature...\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "\n",
      "✓ Completed in 2.6 minutes\n",
      "  Best CV AUC: 0.9997\n",
      "  Best params: {'subsample': 0.8, 'reg_lambda': 1.5, 'reg_alpha': 1.0, 'num_leaves': 50, 'max_depth': 3, 'learning_rate': 0.2, 'colsample_bytree': 0.6}\n",
      "\n",
      "======================================================================\n",
      "COMPARISON: WITH vs WITHOUT LEAKY FEATURE\n",
      "======================================================================\n",
      "\n",
      "AUC Comparison:\n",
      "  WITH 'interest_rate_spread':    0.3899\n",
      "  WITHOUT 'interest_rate_spread': 0.3542\n",
      "  Drop:                           0.0357\n",
      "\n",
      "✓ Feature appears legitimate\n",
      "    Minimal impact when removed\n",
      "    Keep for production (use original model)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CHECKING FOR DATA LEAKAGE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ========== CONVERT TO DATAFRAME IF NEEDED ==========\n",
    "if isinstance(X_train_balanced, np.ndarray):\n",
    "    X_train_balanced = pd.DataFrame(X_train_balanced, columns=feature_names)\n",
    "if isinstance(X_test, np.ndarray):\n",
    "    X_test = pd.DataFrame(X_test, columns=feature_names)\n",
    "\n",
    "# ========== REMOVE SUSPECTED LEAKY FEATURE ==========\n",
    "print(\"\\nRetraining WITHOUT 'Interest_rate_spread'...\")\n",
    "\n",
    "# Drop the suspicious feature\n",
    "X_train_no_leak = X_train_balanced.drop('Interest_rate_spread', axis=1)\n",
    "X_test_no_leak = X_test.drop('Interest_rate_spread', axis=1)\n",
    "\n",
    "feature_names_no_leak = [col for col in feature_names if col != 'Interest_rate_spread']\n",
    "\n",
    "print(f\"Original features: {X_train_balanced.shape[1]}\")\n",
    "print(f\"After removing 'interest_rate_spread': {X_train_no_leak.shape[1]}\")\n",
    "\n",
    "# ========== RETRAIN WITH GRID SEARCH ==========\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_dist = {\n",
    "    'max_depth': [3, 4, 5, 6, 7, 8],\n",
    "    'learning_rate': [0.01, 0.03, 0.05, 0.1, 0.2],\n",
    "    'num_leaves': [20, 31, 50, 63, 100],\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8],\n",
    "    'reg_lambda': [0.5, 1.0, 1.5],\n",
    "    'reg_alpha': [0.0, 0.5, 1.0],\n",
    "}\n",
    "\n",
    "lgb_base = lgb.LGBMClassifier(\n",
    "    n_estimators=200,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=lgb_base,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,\n",
    "    cv=3,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Starting random search without leaky feature...\")\n",
    "start_time = time.time()\n",
    "random_search.fit(X_train_no_leak, y_train_balanced)\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "best_model_no_leak = random_search.best_estimator_\n",
    "\n",
    "print(f\"\\n✓ Completed in {elapsed_time/60:.1f} minutes\")\n",
    "print(f\"  Best CV AUC: {random_search.best_score_:.4f}\")\n",
    "print(f\"  Best params: {random_search.best_params_}\")\n",
    "\n",
    "# ========== EVALUATE WITHOUT LEAKY FEATURE ==========\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPARISON: WITH vs WITHOUT LEAKY FEATURE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Model WITH leaky feature (original)\n",
    "best_pred_with_leak = best_lgb.predict(X_test)\n",
    "best_auc_with_leak = roc_auc_score(y_test, best_lgb.predict_proba(X_test)[:, 1])\n",
    "\n",
    "# Model WITHOUT leaky feature (new)\n",
    "best_pred_no_leak = best_model_no_leak.predict(X_test_no_leak)\n",
    "best_auc_no_leak = roc_auc_score(y_test, best_model_no_leak.predict_proba(X_test_no_leak)[:, 1])\n",
    "\n",
    "print(f\"\\nAUC Comparison:\")\n",
    "print(f\"  WITH 'interest_rate_spread':    {best_auc_with_leak:.4f}\")\n",
    "print(f\"  WITHOUT 'interest_rate_spread': {best_auc_no_leak:.4f}\")\n",
    "print(f\"  Drop:                           {best_auc_with_leak - best_auc_no_leak:.4f}\")\n",
    "\n",
    "# ========== LEAKAGE DIAGNOSIS ==========\n",
    "auc_drop = best_auc_with_leak - best_auc_no_leak\n",
    "\n",
    "if auc_drop > 0.1:\n",
    "    print(f\"\\n⚠️  LEAKAGE CONFIRMED\")\n",
    "    print(f\"    'interest_rate_spread' encodes target information\")\n",
    "    print(f\"    Use model WITHOUT this feature for production\")\n",
    "    print(f\"    True realistic AUC: {best_auc_no_leak:.4f}\")\n",
    "elif auc_drop > 0.05:\n",
    "    print(f\"\\n⚠️  LIKELY LEAKAGE\")\n",
    "    print(f\"    Feature contributes disproportionately to predictions\")\n",
    "    print(f\"    Investigate feature engineering process\")\n",
    "else:\n",
    "    print(f\"\\n✓ Feature appears legitimate\")\n",
    "    print(f\"    Minimal impact when removed\")\n",
    "    print(f\"    Keep for production (use original model)\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc4a76e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
